{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "contrary-palmer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:36.738356Z",
     "start_time": "2021-02-10T20:16:36.726993Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "collectible-december",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:06.332388Z",
     "start_time": "2021-02-10T20:15:53.468536Z"
    }
   },
   "outputs": [],
   "source": [
    "rooth_path = '../rawdata/outro/'\n",
    "generator_df = pd.read_csv(rooth_path + 'generator_df.csv')\n",
    "gen_bear_df = pd.read_csv(rooth_path + 'gen_bear_df.csv')\n",
    "hyd_df = pd.read_csv(rooth_path + 'hyd_df.csv')\n",
    "gearbox_df = pd.read_csv(rooth_path + 'gearbox_df.csv')\n",
    "transf_df = pd.read_csv(rooth_path + 'transf_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "interior-performance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:07.246524Z",
     "start_time": "2021-02-10T20:16:06.336294Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_df['Timestamp'] = pd.to_datetime(generator_df['Timestamp'])\n",
    "gen_bear_df['Timestamp'] = pd.to_datetime(gen_bear_df['Timestamp'])\n",
    "hyd_df['Timestamp'] = pd.to_datetime(hyd_df['Timestamp'])\n",
    "gearbox_df['Timestamp'] = pd.to_datetime(gearbox_df['Timestamp'])\n",
    "transf_df['Timestamp'] = pd.to_datetime(transf_df['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "revised-gardening",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:07.256487Z",
     "start_time": "2021-02-10T20:16:07.250012Z"
    }
   },
   "outputs": [],
   "source": [
    "#By Pearson corr analysis\n",
    "features_drop = ['Gen_RPM_Max', 'Gen_RPM_Min', 'Gen_Phase1_Temp_Avg','Gen_Phase3_Temp_Avg', 'Amb_WindSpeed_Est_Avg',\n",
    "                'Grd_RtrInvPhase1_Temp_Avg', 'Grd_RtrInvPhase3_Temp_Avg', 'Rtr_RPM_Max', 'Rtr_RPM_Min','Grd_Prod_VoltPhse2_Avg',\n",
    "                'Blds_PitchAngle_Max', 'Blds_PitchAngle_Min', 'Prod_LatestAvg_ReactPwrGen1', 'Cont_Hub_Temp_Avg',\n",
    "                'Spin_Temp_Avg', 'Rtr_RPM_Std', 'Rtr_RPM_Avg', 'Cont_VCP_Temp_Avg', 'Grd_Prod_CurPhse1_Avg', 'Prod_LatestAvg_TotActPwr',\n",
    "                 'Grd_Prod_CurPhse3_Avg', 'Grd_Prod_Pwr_Max', 'Grd_Prod_Pwr_Min', 'HVTrafo_Phase1_Temp_Avg', 'Grd_Prod_CurPhse2_Avg',\n",
    "                 'HVTrafo_Phase3_Temp_Avg', 'Grd_Prod_PsblePwr_Max', 'Grd_Prod_PsblePwr_Min', 'Grd_Prod_ReactPwr_Avg',\n",
    "                'Grd_Prod_PsbleInd_Max', 'Grd_Prod_PsbleInd_Min', 'Prod_LatestAvg_ActPwrGen1', 'Prod_LatestAvg_TotReactPwr',\n",
    "                'Grd_Prod_PsbleInd_Avg', 'Blds_PitchAngle_Avg', 'Grd_Prod_ReactPwr_Max', 'Grd_Prod_ReactPwr_Min',\n",
    "                'Nac_Direction_Avg', 'Amb_WindDir_Abs_Avg', 'Grd_Prod_PsbleCap_Min', 'Gear_Oil_Temp_Avg', 'Grd_Prod_VoltPhse1_Avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "seeing-electron",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:07.520802Z",
     "start_time": "2021-02-10T20:16:07.259174Z"
    }
   },
   "outputs": [],
   "source": [
    "## Remove columns with strong correlations\n",
    "generator_df = generator_df.drop(columns=features_drop)\n",
    "gen_bear_df = gen_bear_df.drop(columns=features_drop)\n",
    "hyd_df = hyd_df.drop(columns=features_drop)\n",
    "gearbox_df = gearbox_df.drop(columns=features_drop)\n",
    "transf_df = transf_df.drop(columns=features_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dietary-spencer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:07.533382Z",
     "start_time": "2021-02-10T20:16:07.526216Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_train_test(df):\n",
    "    last_date = df['Timestamp'].iloc[-1]\n",
    "    split = last_date - pd.DateOffset(months=3)\n",
    "    df_train = df[df['Timestamp'] < split]\n",
    "    df_test = df[df['Timestamp'] >= split]\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aging-nepal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:07.995756Z",
     "start_time": "2021-02-10T20:16:07.535940Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_df_train, generator_df_test = prepare_train_test(generator_df)\n",
    "gen_bear_df_train, gen_bear_df_test = prepare_train_test(gen_bear_df)\n",
    "hyd_df_train, hyd_df_test = prepare_train_test(hyd_df)\n",
    "gearbox_df_train, gearbox_df_test = prepare_train_test(gearbox_df)\n",
    "transf_df_train, transf_df_test = prepare_train_test(transf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "solid-movie",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:08.006747Z",
     "start_time": "2021-02-10T20:16:08.000306Z"
    }
   },
   "outputs": [],
   "source": [
    "#Group by day per turbine\n",
    "def group_per_frequency(df, strategy='mean'):\n",
    "    df['Date'] = df['Timestamp'].dt.date\n",
    "    if strategy == 'max':\n",
    "        df = df.groupby(by=['Turbine_ID','Date']).max().reset_index().drop(columns='Timestamp')\n",
    "    else:\n",
    "        df = df.groupby(by=['Turbine_ID','Date']).mean().reset_index()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "rental-moore",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:09.333167Z",
     "start_time": "2021-02-10T20:16:08.013070Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.pyenv/versions/3.7.2/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_train_gearbox_day = group_per_frequency(gearbox_df_train)\n",
    "df_train_gen_day = group_per_frequency(generator_df_train)\n",
    "df_train_gen_bear_day = group_per_frequency(gen_bear_df_train)\n",
    "df_train_hyd_day = group_per_frequency(hyd_df_train)\n",
    "df_train_transf_day = group_per_frequency(transf_df_train)\n",
    "df_test_gearbox_day = group_per_frequency(gearbox_df_test)\n",
    "df_test_gen_day = group_per_frequency(generator_df_test)\n",
    "df_test_gen_bear_day = group_per_frequency(gen_bear_df_test)\n",
    "df_test_hyd_day = group_per_frequency(hyd_df_test)\n",
    "df_test_transf_day = group_per_frequency(transf_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "historical-start",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:09.347441Z",
     "start_time": "2021-02-10T20:16:09.335704Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = [df_train_gearbox_day,df_train_gen_day, df_train_gen_bear_day, df_train_hyd_day, df_train_transf_day,\n",
    "       df_test_gearbox_day, df_test_gen_day, df_test_gen_bear_day, df_test_hyd_day, df_test_transf_day ]\n",
    "\n",
    "for df in dfs:\n",
    "    df['60_days'] = df['60_days'].round(decimals=0)\n",
    "#     df['50_days'] = df['50_days'].round(decimals=0)\n",
    "#     df['40_days'] = df['40_days'].round(decimals=0)\n",
    "#     df['30_days'] = df['30_days'].round(decimals=0)\n",
    "#     df['20_days'] = df['20_days'].round(decimals=0)\n",
    "#     df['10_days'] = df['10_days'].round(decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "utility-genius",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:09.368178Z",
     "start_time": "2021-02-10T20:16:09.350651Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_features(df_in, rolling_win_size):\n",
    "    \n",
    "    sensor_cols = []\n",
    "    for i in df_in.keys()[2:-3]:\n",
    "        sensor_cols.append(i)\n",
    "    sensor_av_cols = [nm+'_av' for nm in sensor_cols]\n",
    "    sensor_sd_cols = [nm+'_sd' for nm in sensor_cols]\n",
    "    df_out = pd.DataFrame()\n",
    "    ws = rolling_win_size\n",
    "    #calculate rolling stats for each engine id\n",
    "    for m_id in pd.unique(df_in.Turbine_ID):\n",
    "        # get a subset for each engine sensors\n",
    "        df_engine = df_in[df_in['Turbine_ID'] == m_id]\n",
    "        df_sub = df_engine[sensor_cols]\n",
    "        # get rolling mean for the subset\n",
    "        av = df_sub.rolling(ws, min_periods=1).mean()\n",
    "        av.columns = sensor_av_cols\n",
    "        # get the rolling standard deviation for the subset\n",
    "        sd = df_sub.rolling(ws, min_periods=1).std().fillna(0)\n",
    "        sd.columns = sensor_sd_cols\n",
    "        # combine the two new subset dataframes columns to the engine subset\n",
    "        new_ftrs = pd.concat([df_engine,av,sd], axis=1)\n",
    "        # add the new features rows to the output dataframe\n",
    "        df_out = pd.concat([df_out,new_ftrs])\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "banned-scoop",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:09.956114Z",
     "start_time": "2021-02-10T20:16:09.371462Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_gearbox_extra = add_features(df_train_gearbox_day, 60)\n",
    "df_train_gen_extra = add_features(df_train_gen_day, 60)\n",
    "df_train_gen_bear_extra = add_features(df_train_gen_bear_day, 60)\n",
    "df_train_hyd_extra = add_features(df_train_hyd_day, 60)\n",
    "df_train_transf_extra = add_features(df_train_transf_day, 60)\n",
    "df_test_gearbox_extra = add_features(df_test_gearbox_day, 60)\n",
    "df_test_gen_extra = add_features(df_test_gen_day, 60)\n",
    "df_test_gen_bear_extra = add_features(df_test_gen_bear_day, 60)\n",
    "df_test_hyd_extra = add_features(df_test_hyd_day, 60)\n",
    "df_test_transf_extra = add_features(df_test_transf_day, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "premier-formation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:09.964506Z",
     "start_time": "2021-02-10T20:16:09.959178Z"
    }
   },
   "outputs": [],
   "source": [
    "#Failures Generator in train data - T06 and T11\n",
    "#Failures Hydraulic Group in train data - T06 and T11\n",
    "#Failures Gen_bear in train data - T07 and T09\n",
    "#Failures Transformer in train data - T07\n",
    "# Gearbox -> Change train_test in order to be 1 failure in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "irish-juvenile",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:09.993010Z",
     "start_time": "2021-02-10T20:16:09.968408Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_gen = df_train_gen_extra.loc[(df_train_gen_extra['Turbine_ID']=='T06') | (df_train_gen_extra['Turbine_ID']=='T11')]\n",
    "df_train_gen_bear = df_train_gen_bear_extra.loc[(df_train_gen_bear_extra['Turbine_ID']=='T07') | (df_train_gen_bear_extra['Turbine_ID']=='T09')]\n",
    "df_train_hyd = df_train_hyd_extra.loc[(df_train_hyd_extra['Turbine_ID']=='T06') | (df_train_hyd_extra['Turbine_ID']=='T11')]\n",
    "df_train_transf = df_train_transf_extra.loc[df_train_transf_extra['Turbine_ID']=='T07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "liked-electric",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T20:16:10.008389Z",
     "start_time": "2021-02-10T20:16:09.996252Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_gen = df_test_gen_extra.copy()\n",
    "df_test_gen_bear = df_test_gen_bear_extra.copy()\n",
    "df_test_hyd = df_test_hyd_extra.copy()\n",
    "df_test_transf = df_test_transf_extra.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "generous-journal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T21:33:26.493139Z",
     "start_time": "2021-02-10T21:33:26.477936Z"
    }
   },
   "outputs": [],
   "source": [
    "#Scaling\n",
    "def scale(df_train, df_test, scaler='StandardScaler'):\n",
    "    \n",
    "    for m_id in pd.unique(df_train.Turbine_ID):\n",
    "        X_train = df_train.drop(columns=['Date', 'TTF', '60_days', 'Component', 'Turbine_ID']) \n",
    "        X_test = df_test.drop(columns=['Date', 'TTF', '60_days', 'Component', 'Turbine_ID'])\n",
    "        if scaler == 'MinMaxScaler':\n",
    "            sc = MinMaxScaler()\n",
    "            X_train_scale = sc.fit_transform(X_train)\n",
    "            X_test_scale = sc.transform(X_test)\n",
    "        else:\n",
    "            sc = StandardScaler()\n",
    "            X_train_scale = sc.fit_transform(X_train)\n",
    "            X_test_scale = sc.transform(X_test)\n",
    "\n",
    "        \n",
    "    return X_train_scale, X_test_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "graduate-terrain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T19:58:19.344546Z",
     "start_time": "2021-02-10T19:58:19.329554Z"
    }
   },
   "outputs": [],
   "source": [
    "def bin_classify(model, clf, X_train, X_test, y_train, y_test, params=None, score=None, ):\n",
    "      \n",
    "        \n",
    "    grid_search = model_selection.GridSearchCV(estimator=clf, param_grid=params, cv=5, scoring=score, n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    if hasattr(grid_search, 'predict_proba'):   \n",
    "        y_score = grid_search.predict_proba(X_test)[:,1]\n",
    "    elif hasattr(grid_search, 'decision_function'):\n",
    "        y_score = grid_search.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = y_pred\n",
    "        \n",
    "    predictions = {'y_pred' : y_pred, 'y_score' : y_score}\n",
    "    df_predictions = pd.DataFrame.from_dict(predictions)\n",
    "    \n",
    "    return grid_search.best_estimator_, df_predictions, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "technological-pilot",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T19:58:19.361391Z",
     "start_time": "2021-02-10T19:58:19.347361Z"
    }
   },
   "outputs": [],
   "source": [
    "def metrics (y_test, y_test_pred):\n",
    "    cm2 = confusion_matrix(y_test.values,y_test_pred)\n",
    "\n",
    "    total1=sum(sum(cm2))\n",
    "    \n",
    "    \n",
    "    metrics_dict = {\n",
    "    'AUC_Test': roc_auc_score(y_test, y_test_pred) if len(y_test.value_counts())>1 else np.nan,\n",
    "    'Accuracy':     (cm2[0,0]+cm2[1,1])/total1 if len(y_test.value_counts())>1 else np.nan,\n",
    "    'Recall': cm2[1,1]/(cm2[1,0]+cm2[1,1]) if len(y_test.value_counts())>1 else np.nan,\n",
    "    'Specificity':  cm2[0,0]/(cm2[0,0]+cm2[0,1]) if len(y_test.value_counts())>1 else np.nan,\n",
    "    'Precision':    cm2[1,1]/(cm2[0,1]+cm2[1,1]) if len(y_test.value_counts())>1 else np.nan,\n",
    "    'F1 Score':    f1_score(y_test,y_test_pred) if len(y_test.value_counts())>1 else np.nan,\n",
    "        }\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "american-happiness",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T21:17:23.842813Z",
     "start_time": "2021-02-10T21:17:23.823441Z"
    }
   },
   "outputs": [],
   "source": [
    "def conf_matrix ( y_test, y_test_pred):\n",
    "\n",
    "    return pd.crosstab(y_test, y_test_pred, rownames=['Actual Class'], colnames=['Predicted Class'])\n",
    "\n",
    "    sns.set(style='white')\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_test_prob)\n",
    "    plt.plot(fpr, tpr, label='model')\n",
    "    plt.legend(loc='center right')\n",
    "    plt.plot([0,1],[0,1],'k')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.crosstab(y_test, y_test_pred, rownames=['Actual Class'], colnames=['Predicted Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator 30 days\n",
    "model = 'Random Forest Classifier'\n",
    "clf_rfc = RandomForestClassifier(random_state=42)\n",
    "gs_params = {'n_estimators': [100, 200, 300, 500, 750, 800, 1000, 1500], 'criterion': ['gini', 'entropy'], 'class_weight': ['balanced', None]}\n",
    "gs_score = 'recall'\n",
    "\n",
    "clf_rfc, pred_rfc, y_test = bin_classify(model, clf_rfc, gen_final_train, gen_final_test, '60_days', params=gs_params, score=gs_score)\n",
    "print('\\nBest Parameters:\\n',clf_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
